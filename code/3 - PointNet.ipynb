{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1bqXlAsuafy"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQJe7FU7zCok"
   },
   "outputs": [],
   "source": [
    "#set figure size for notebook\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27) ,'savefig.dpi':400})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqY5RMSRzTeO",
    "outputId": "eabe4266-55f3-4813-ec5f-23a3eea00ee9"
   },
   "outputs": [],
   "source": [
    "#import google drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4YwJni3lIAn"
   },
   "outputs": [],
   "source": [
    "#open file\n",
    "with open('/content/drive/MyDrive/data/pc_data.txt') as f:\n",
    "    pointcloud_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2909GJLbJJCU",
    "outputId": "9af42b1a-b636-4a66-d6ae-f12216d8c248"
   },
   "outputs": [],
   "source": [
    "#check dictionary items\n",
    "dict_items = pointcloud_data.items()\n",
    "\n",
    "first_two = list(dict_items)[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LouPqtrqQl2"
   },
   "outputs": [],
   "source": [
    "#create X and y from json \n",
    "X = []\n",
    "y = []\n",
    "for x in pointcloud_data:\n",
    "  X.append(pointcloud_data[x]['pointcloud'])\n",
    "  y.append(pointcloud_data[x]['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "veEZ-sswsXBK",
    "outputId": "e48f352c-8b74-46c7-ef57-2b69e051c405"
   },
   "outputs": [],
   "source": [
    "#check the length of X and y to ensure proper unpacking of json file \n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pkv4TDPYAHK"
   },
   "outputs": [],
   "source": [
    "#unnest pointcloud arrays\n",
    "\n",
    "X = [item for sublist in X for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6QVuvRms4y2"
   },
   "outputs": [],
   "source": [
    "\n",
    "#find max length of point cloud vectors \n",
    "def FindMinMaxLength(x,min_size,max_size):\n",
    "  max_length = min_size\n",
    "  min_length = max_size\n",
    "  for a in range(len(x)):\n",
    "    if len(x[a]) > max_length:\n",
    "      max_length = len(x[a])\n",
    "      max_a = a\n",
    "    elif len(x[a]) < min_length:\n",
    "      min_length = len(x[a])\n",
    "      min_a = a\n",
    "  print (\"Maximum Point Cloud Vector is \" + str(max_length) +\" and is labelled: \"+\n",
    "         str(y[max_a])+\"\\nMinimum Point Cloud Vector is \" + str(min_length) + \n",
    "         \" and is labelled :\" + str(y[min_a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uC-TZlOBtnX6",
    "outputId": "aa144f36-1221-4de7-c7c1-b995baf6487f"
   },
   "outputs": [],
   "source": [
    "FindMinMaxLength(X,0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Az0m5YaIfAOz"
   },
   "outputs": [],
   "source": [
    "#Function to save point cloud size as list \n",
    "\n",
    "def CalculateSize(x):\n",
    "  Sizes = []\n",
    "  for a in range(len(x)):\n",
    "    Sizes.append(len(x[a]))\n",
    "  return Sizes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOhFKIC8fbeZ"
   },
   "outputs": [],
   "source": [
    "#create list of vector sizes\n",
    "VectorSizes = CalculateSize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "yMzyuC2ufj8Q",
    "outputId": "89df1bc3-d45f-48ff-ed74-aa6e11af9c71"
   },
   "outputs": [],
   "source": [
    "#plot histogram of vector sizes \n",
    "sns.histplot(VectorSizes).set(title=\"Distribution of Point Cloud Vector Sizes\")\n",
    "plt.xlabel(\"Number of Dots in Point Cloud\")\n",
    "plt.savefig(\"Vector_Size.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "gkfMpKP2xnDO",
    "outputId": "785b2f59-715d-4251-a637-05eba0c4fb2e"
   },
   "outputs": [],
   "source": [
    "#visualize class distribution\n",
    "\n",
    "\n",
    "merged_labels = list(itertools.chain(*y))\n",
    "sns.histplot(merged_labels).set(title=\"Number of Objects per Class in the Nuscenes Mini Dataset\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Category Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Category_Count.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQkG-3C1Cc_-"
   },
   "outputs": [],
   "source": [
    "#create df of class with vector size\n",
    "\n",
    "ClassSize = pd.DataFrame(list(zip(merged_labels,VectorSizes)), columns =['Category', 'Size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "og9leB5qkAhy",
    "outputId": "15858a7a-0c63-413c-c157-21f06dad9a00"
   },
   "outputs": [],
   "source": [
    "#plot histogram of cloud sizes by category label\n",
    "sns.histplot(data=ClassSize, x=\"Size\", hue=\"Category\").set(title=\"Histogram of Point Cloud Vector Size per Category\")\n",
    "plt.savefig(\"Category_Size.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQaXHXGhHDIa"
   },
   "outputs": [],
   "source": [
    "#function reshape vectors to x,y,z arrays \n",
    "\n",
    "def ReshapeVectors(x):\n",
    "  for a in range(len(x)):\n",
    "    dots = len(X[a])\n",
    "    x[a] = np.asarray(x[a])\n",
    "    x[a]  = np.transpose((x[a]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8lVqWVcnWH8"
   },
   "outputs": [],
   "source": [
    "    #reshape vectors \n",
    "    ReshapeVectors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBR6wo8mFu8s"
   },
   "outputs": [],
   "source": [
    "#function to pad vectors to equal length \n",
    "\n",
    "def PadClouds(x, length):\n",
    "  for a in range(len(x)):\n",
    "    x[a] = pad_sequences(\n",
    "    x[a], maxlen=length, dtype='float64', padding='pre',\n",
    "    truncating='pre', value=0.0) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPdUuD_Zvhv4"
   },
   "outputs": [],
   "source": [
    "#pad vectors to 1024 as the average length that will preserve most vectors \n",
    "#and is the PointNet standard\n",
    "\n",
    "PadClouds(X,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1xAPIyh-xRl"
   },
   "outputs": [],
   "source": [
    "#function to check length of padded vectors and ensure same length \n",
    "\n",
    "def FindMinMaxLengthDos(x):\n",
    "  max_length = 0\n",
    "  min_length = 1025\n",
    "  for a in range(len(x)):\n",
    "      if len(x[a][0]) > max_length:\n",
    "        max_length = len(x[a][0])\n",
    "        max_a = a\n",
    "      elif len(x[a][0]) < min_length:\n",
    "        min_length = len(x[a][0])\n",
    "        min_a = a\n",
    "  print (\"Maximum Cloud Point Vector is \" + str(max_length) +\" and is labelled: \"+\n",
    "         str(y[max_a])+\"\\nMinimum Cloud Point Vector is \" + str(min_length) + \n",
    "         \" and is labelled :\" + str(y[min_a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srHB0jzG-ULe",
    "outputId": "6ceef8c3-f5e2-4144-fbde-287ac8fd0695"
   },
   "outputs": [],
   "source": [
    "#check for equal length in all vectors\n",
    "\n",
    "FindMinMaxLengthDos(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VuvBzl4-m8I"
   },
   "outputs": [],
   "source": [
    "#Function Normalize point cloud values\n",
    "\n",
    "def NormalizePointClouds(x):\n",
    "  for a in range(len(x)):\n",
    "    for b in range(len(x[a])):\n",
    "      norm = np.linalg.norm(x[a][b])\n",
    "      x[a][b] = x[a][b]/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXLBxcJqBpia"
   },
   "outputs": [],
   "source": [
    "#Normalize point cloud values for modeling\n",
    "NormalizePointClouds(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdYXbJJXalhg"
   },
   "outputs": [],
   "source": [
    "#reshape vectors back to [x,y,z] values for each point \n",
    "\n",
    "ReshapeVectors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxaJdIcaeQlh"
   },
   "outputs": [],
   "source": [
    "#unnest list of category labels \n",
    "y_list = [item for sublist in y for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohkMj_xIdLS4",
    "outputId": "40b3779b-fad5-415f-bafd-5418336bee84"
   },
   "outputs": [],
   "source": [
    "\n",
    "#encode all y labels to int for modelling\n",
    "LE = LabelEncoder()\n",
    "y_encoded = LE.fit_transform(y_list)\n",
    "\n",
    "#create dictionary of encoded labels\n",
    "le_name_mapping = dict(zip(LE.classes_, LE.transform(LE.classes_)))\n",
    "\n",
    "#reverse key and value\n",
    "le_map = {v: k for k, v in le_name_mapping.items()}\n",
    "\n",
    "#print encode keys \n",
    "print(le_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmUCo3yKr9pG"
   },
   "outputs": [],
   "source": [
    "#keep only \"vehicle_car\" class for binary classification\n",
    "\n",
    "y_encoded[y_encoded != 10] = 0\n",
    "y_encoded[y_encoded == 10] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "ZIAVOdO31bsm",
    "outputId": "1989c10a-6dbb-4f57-c52b-c667cd984fca"
   },
   "outputs": [],
   "source": [
    "#visualize class distribution\n",
    "\n",
    "\n",
    "sns.histplot(y_encoded, binwidth=0.5).set(title=\"Binary Class Category for Modeling\")\n",
    "plt.savefig(\"Binary_Hist.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MojFv0QzBuxz"
   },
   "outputs": [],
   "source": [
    "#split data into train and test \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.33, random_state=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k46XZklfCTi1"
   },
   "outputs": [],
   "source": [
    "#augment cloud point vectors by jittering and randomizing \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 1\n",
    "NUM_POINTS = 1024\n",
    "\n",
    "def augment(points, label):\n",
    "    # jitter points\n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    # shuffle points\n",
    "    points = tf.random.shuffle(points)\n",
    "    return points, label\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(len(X_train)).map(augment).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.shuffle(len(X_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4YFnCjp_P8Q"
   },
   "outputs": [],
   "source": [
    "#set random seed\n",
    "tf.random.set_seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "md9FQeeEVbsF"
   },
   "outputs": [],
   "source": [
    "#create convolutional layers\n",
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "#create dense layers\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LR7P9iRoVsQU"
   },
   "outputs": [],
   "source": [
    "#create orthogonal class\n",
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmiBuT0KVwb1"
   },
   "outputs": [],
   "source": [
    "#create function to initialize tnet\n",
    "def tnet(inputs, num_features):\n",
    "\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emOsHcJHVzhj",
    "outputId": "400d3239-7264-4f1f-be23-14c060ae8c5b"
   },
   "outputs": [],
   "source": [
    "#initiate model\n",
    "inputs = keras.Input(shape=(NUM_POINTS,3))\n",
    "\n",
    "x = tnet(inputs, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "\n",
    "#get model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbTkNCu8V72p",
    "outputId": "721765cb-40b7-4276-fae7-8df2015434dd"
   },
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "# create patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "\n",
    "#train and fit model on data\n",
    "PointNet = model.fit(train_dataset, epochs=200, validation_data=test_dataset, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlzQxI6IWj00"
   },
   "outputs": [],
   "source": [
    "#create map of category labels \n",
    "bin_map = {0: 'Noise', 1:'Car'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "-41-Wi8qXhKW",
    "outputId": "e49b023e-f0f4-4f94-b3c3-9303089dd331"
   },
   "outputs": [],
   "source": [
    "#visualize prediction and actual label for point cloud vectors \n",
    "data = test_dataset.take(1)\n",
    "\n",
    "points, labels = list(data)[0]\n",
    "points = points[:8, ...]\n",
    "labels = labels[:8, ...]\n",
    "\n",
    "# run test data through model\n",
    "preds = model.predict(points)\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "\n",
    "points = points.numpy()\n",
    "\n",
    "# plot points with predicted class and label\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
    "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n",
    "    ax.set_title(\n",
    "        \"pred: {:} \\n label: {:}\".format(\n",
    "            bin_map[preds[i].numpy()], bin_map[labels.numpy()[i]]\n",
    "        )\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "GpJfIBEO_HNF",
    "outputId": "a04983e1-7d7e-4583-d4ea-061e1cbae2fe"
   },
   "outputs": [],
   "source": [
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(PointNet.history['loss'], label='train')\n",
    "plt.plot(PointNet.history['val_loss'], label='test')\n",
    "\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(PointNet.history['accuracy'], label='train')\n",
    "plt.plot(PointNet.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_accuracy.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhZKvILL6m2Y"
   },
   "outputs": [],
   "source": [
    "PointNet adapted from Keras:\n",
    "\n",
    "https://keras.io/examples/vision/pointnet/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 3 - PointNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

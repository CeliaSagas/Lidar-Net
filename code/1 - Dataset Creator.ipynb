{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac944054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm \n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import os.path as osp\n",
    "from nuscenes import NuScenes\n",
    "\n",
    "# Utils to use NuScenes\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "from nuscenes.utils.data_classes import RadarPointCloud\n",
    "from utils.misc import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14901c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /users/CeliaSagastume/Desktop/Lidar-Net/data/sets/nuscenes\n",
    "!tar -xf v1.0-mini.tgz -C /users/CeliaSagastume/Desktop/Lidar-Net/data/sets/nuscenes  # Uncompress the nuScenes mini split.\n",
    "!tar -xf nuScenes-lidarseg-mini-v1.0.tar.bz2 -C /users/CeliaSagastume/Desktop/Lidar-Net/data/sets/nuscenes   # Uncompress the nuScenes-lidarseg mini split.\n",
    "\n",
    "!pip install nuscenes-devkit &> /dev/null  # Install nuScenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d635180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nuscenes_root = \"/users/CeliaSagastume/Desktop/Lidar-Net/data/sets/nuscenes\"\n",
    "\n",
    "from nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot=nuscenes_root, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374558cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Obtain all annotation boxes from dataset with corresponding data from sensor\n",
    "\n",
    "def Get_Data(sensor):\n",
    "\n",
    "    # Define sensor data to be saved \n",
    "    Sensor_data = sensor\n",
    "\n",
    "    # Define number of samples from dataset total\n",
    "    samples = np.array(nusc.sample).shape\n",
    "\n",
    "    # Define path for point clouds \n",
    "    pc_folder = os.getcwd() + '/dataset/lidar/'\n",
    "\n",
    "    # Define path for JSON information files \n",
    "    sample_folder = os.getcwd() + '/dataset/samples/'\n",
    "\n",
    "    # Define path for segmentation files \n",
    "    pcd_segmentation_path =  os.getcwd() + '/dataset/pcd_segmentation/'\n",
    "\n",
    "    for sample_idx in tqdm(range(samples[0]), desc = \"Sample files\"):\n",
    "\n",
    "        # Define current sample\n",
    "        current_sample = nusc.sample[sample_idx]\n",
    "\n",
    "        # Get point cloud for current sample \n",
    "        point_data = nusc.get('sample_data', current_sample['data'][sensor_laser])\n",
    "\n",
    "        # Get all annotations for current sample \n",
    "        annotations = current_sample['anns']\n",
    "\n",
    "        # Create dictionary to store all inormation in JSON for each sample\n",
    "        data_json = {}\n",
    "        data_json['instance'] = []\n",
    "\n",
    "        # Loop over all the annotations\n",
    "        for ann in annotations:\n",
    "            # Obtain current annotation\n",
    "            annotation_metadata =  nusc.get('sample_annotation', ann)\n",
    "\n",
    "            category_name = annotation_metadata['category_name'].replace(\".\", \"_\")\n",
    "\n",
    "            # Exclude samples that do not have visibility > 80% (category 4)\n",
    "            if (int(annotation_metadata['visibility_token'])) < 4 : \n",
    "                continue\n",
    "\n",
    "            # Obtain the camera channel\n",
    "            camera_channel = get_camera_data(nusc, annotation_metadata['token'])\n",
    "\n",
    "            # Extract the sample_data giving the interest camera\n",
    "            cam_data = nusc.get('sample_data', current_sample['data'][camera_channel])\n",
    "\n",
    "            # Additional filter to detect if the frame is a keyframe\n",
    "            if cam_data['is_key_frame'] != True:\n",
    "                continue\n",
    "\n",
    "            # Obtain the target for the given instance \n",
    "            target_box = target_to_cam(nusc, point_data['token'], ann, pointsensor_channel = sensor_laser)\n",
    "\n",
    "            # Compute the 2d bounding box of the current annotation\n",
    "            bbox = bbox_3d_to_2d(nusc, camera_token = cam_data['token'], annotation_token = ann, visualize = False)\n",
    "\n",
    "            # Break the loop if the bbox is not intersected with the current image channel\n",
    "            if bbox is None:\n",
    "                continue\n",
    "\n",
    "            # Map the velo pointcloud to the interest instance\n",
    "            points, coloring, ori_points, im = map_pointcloud_to_image_(nusc, bbox, point_data['token'], \n",
    "                                                                        cam_data['token'], dist_thresh = 0.08,\n",
    "                                                                        visualize = False)\n",
    "\n",
    "\n",
    "            # If the pointcloud is empty or there are less than 20 points, continue\n",
    "            if np.array(ori_points).shape[1] == 0 or np.array(ori_points).shape[1] < 100:\n",
    "                continue        \n",
    "\n",
    "            # Dataroot for PointCloud .txt file using the annotation token\n",
    "            pc_path = pc_folder + 'pc_anno_' + annotation_metadata['token'] + '.txt'\n",
    "\n",
    "            # save the Pointcloud in a .txt file\n",
    "            save_to_txt(pc_path, ori_points)\n",
    "\n",
    "            #  PointCloud in camera frame plus coloring row\n",
    "            points_coloring = np.vstack([points, np.transpose(coloring)])\n",
    "\n",
    "            # Append the information for each annotation\n",
    "            data_json['instance'].append({\n",
    "                'annotation_token': annotation_metadata['token'],\n",
    "                'sample_token' : current_sample['token'],\n",
    "                'pointcloud_path': pc_path,\n",
    "                'pcl_shape': np.array(ori_points).shape,\n",
    "                'pcd_path': pcd_segmentation_path+'pcd_segmentation_'+annotation_metadata['token']+'.pcd',\n",
    "                'position_coord': [target_box.center[0], target_box.center[1], target_box.center[2]],\n",
    "                'wlh_values': annotation_metadata['size'],\n",
    "                'orientation_value': target_box.orientation.degrees,\n",
    "                'rotation_axis': target_box.orientation.axis[2],\n",
    "                'category': category_name\n",
    "            })\n",
    "\n",
    "        file_name= 'sample_'+ current_sample['token'] + '_file.txt'\n",
    "        # Save the dictionary in a .txt file in JSON format for each sample       \n",
    "        save_in_file(sample_folder + file_name, data_json)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc8a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Get_Data('LIDAR_TOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e8709",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset and Instance segmentation adapted from:\n",
    "\n",
    "@misc{salazargomez2021highlevel,\n",
    "      title={High-level camera-LiDAR fusion for 3D object detection with machine learning},\n",
    "      author={Gustavo A. Salazar-Gomez and Miguel A. Saavedra-Ruiz and Victor A. Romero-Cano},\n",
    "      year={2021},\n",
    "      eprint={2105.11060},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CV}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
